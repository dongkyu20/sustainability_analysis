#!/usr/bin/env python3
"""
Ollama ì„¤ì¹˜ ë° ì„¤ì • ë„ìš°ë¯¸ ìŠ¤í¬ë¦½íŠ¸
"""

import subprocess
import requests
import time
import platform
import sys
import config

def check_ollama_installed():
    """Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    try:
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print(f"âœ… Ollama is installed: {result.stdout.strip()}")
            return True
        else:
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return False

def install_ollama():
    """ìš´ì˜ì²´ì œë³„ Ollama ì„¤ì¹˜ ì•ˆë‚´"""
    system = platform.system().lower()
    
    print("ğŸ“¥ Ollama is not installed. Please install it:")
    print()
    
    if system == "darwin":  # macOS
        print("ğŸ macOS:")
        print("   Method 1: Download from https://ollama.ai/")
        print("   Method 2: brew install ollama")
        
    elif system == "linux":
        print("ğŸ§ Linux:")
        print("   curl -fsSL https://ollama.ai/install.sh | sh")
        
    elif system == "windows":
        print("ğŸªŸ Windows:")
        print("   Download from https://ollama.ai/")
        
    print()
    print("After installation, run: ollama serve")
    return False

def check_ollama_running():
    """Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    try:
        response = requests.get(f"{config.OLLAMA_BASE_URL}/api/tags", timeout=3)
        if response.status_code == 200:
            print("âœ… Ollama server is running")
            return True
        else:
            print(f"âŒ Ollama server responded with status: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ Ollama server is not running")
        print("ğŸ’¡ Please run: ollama serve")
        return False
    except Exception as e:
        print(f"âŒ Error checking Ollama server: {str(e)}")
        return False

def start_ollama_server():
    """Ollama ì„œë²„ ì‹œì‘ ì‹œë„"""
    print("ğŸš€ Attempting to start Ollama server...")
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ollama serve ì‹¤í–‰
        process = subprocess.Popen(['ollama', 'serve'], 
                                 stdout=subprocess.DEVNULL, 
                                 stderr=subprocess.DEVNULL)
        
        # ì„œë²„ê°€ ì‹œì‘ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
        print("â³ Waiting for server to start...")
        time.sleep(3)
        
        if check_ollama_running():
            print(f"âœ… Ollama server started with PID: {process.pid}")
            return True
        else:
            print("âŒ Failed to start Ollama server")
            return False
            
    except FileNotFoundError:
        print("âŒ 'ollama serve' command not found")
        return False
    except Exception as e:
        print(f"âŒ Error starting Ollama server: {str(e)}")
        return False

def pull_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    model = config.OLLAMA_EMBEDDING_MODEL
    print(f"ğŸ“¥ Pulling embedding model: {model}")
    
    try:
        # ollama pull ëª…ë ¹ ì‹¤í–‰
        process = subprocess.Popen(['ollama', 'pull', model], 
                                 stdout=subprocess.PIPE, 
                                 stderr=subprocess.PIPE, 
                                 text=True)
        
        print("â³ Downloading model... This may take several minutes.")
        
        # ì‹¤ì‹œê°„ ì¶œë ¥
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                print(f"   {output.strip()}")
        
        if process.returncode == 0:
            print(f"âœ… Model {model} downloaded successfully")
            return True
        else:
            stderr = process.stderr.read()
            print(f"âŒ Failed to download model: {stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ Error downloading model: {str(e)}")
        return False

def check_model_available():
    """ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸"""
    try:
        response = requests.get(f"{config.OLLAMA_BASE_URL}/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [model['name'].split(':')[0] for model in models]
            
            if config.OLLAMA_EMBEDDING_MODEL in model_names:
                print(f"âœ… Model {config.OLLAMA_EMBEDDING_MODEL} is available")
                return True
            else:
                print(f"âŒ Model {config.OLLAMA_EMBEDDING_MODEL} not found")
                return False
        else:
            print(f"âŒ Failed to check models: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Error checking models: {str(e)}")
        return False

def setup_ollama():
    """Ollama ì „ì²´ ì„¤ì •"""
    print("ğŸ”§ Setting up Ollama for code embedding...")
    print()
    
    # 1. Ollama ì„¤ì¹˜ í™•ì¸
    if not check_ollama_installed():
        install_ollama()
        return False
    
    # 2. ì„œë²„ ì‹¤í–‰ í™•ì¸
    if not check_ollama_running():
        if not start_ollama_server():
            print("ğŸ’¡ Please manually run: ollama serve")
            return False
    
    # 3. ëª¨ë¸ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    if not check_model_available():
        if not pull_embedding_model():
            return False
    
    print()
    print("ğŸ‰ Ollama setup completed successfully!")
    print("ğŸš€ You can now run the code embedding tool.")
    
    return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) > 1 and sys.argv[1] == '--check':
        # ì„¤ì • ìƒíƒœë§Œ í™•ì¸
        print("ğŸ” Checking Ollama setup...")
        installed = check_ollama_installed()
        running = check_ollama_running() if installed else False
        model_ready = check_model_available() if running else False
        
        print(f"   Installed: {'âœ…' if installed else 'âŒ'}")
        print(f"   Running: {'âœ…' if running else 'âŒ'}")
        print(f"   Model Ready: {'âœ…' if model_ready else 'âŒ'}")
        
        if installed and running and model_ready:
            print("ğŸ‰ Everything is ready!")
        else:
            print("âš ï¸ Setup required. Run without --check flag to setup.")
    else:
        # ì „ì²´ ì„¤ì • ì‹¤í–‰
        setup_ollama()

if __name__ == "__main__":
    main()